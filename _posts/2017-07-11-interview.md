---
layout: post
title:  "Interview"
date:   2017-07-12 00:00:32 +0900
categories: Interview
tags:
hidden: false
---
## 자료구조
#### map vs unoredered_map
* map은 Red-Black Tree를 사용해서 키의 순서를 유지하는 반면 unordered_map은 해시 테이블을 사용해 키의 순서를 유지하지 않음
* 탐색 속도는 N이 작을 때는 map이 다소 빠르지만 반대의 경우에는 unordered_map이 유리
* map은 캐시 미스의 영향을 더 빨리 받는다. 특정 N구간에서 검색속도가 급격히 느려지는 부분이 발생
* unordered_map은 해시 함수의 성능이 중요하다. 하위 b비트의 고른 분포가 중요
* 문자열 키를 사용하는 경우 map이 더 큰 N까지 우위. 문자열 비교에 적은 비교 횟수를 필요로 하기 때문
* 문자열 길이가 길고 데이터 크기가 크지 않은 경우에는 map이 unordered_map보다 탐색이 유리

## 메모리 영역
#### 데이터 영역
* 전역 변수와 static 변수가 할당되는 영역
* 프로그램의 시작과 동시에 할당되고, 프로그램이 종료되어야 메모리에서 소멸

#### 스택 영역
* 함수 호출시 생성되는 지역 변수와 매개 변수가 저장되는 영역
* 함수 호출이 완료되면 사라짐

#### 힙 영역
* 필요에 의해 동적으로 메모리를 할당할 때 사용
* 할당해야 할 메모리의 크기를 프로그램이 실행되는 동안 결정해야 하는 경우(런타임때) 유용하게 사용되는 공간

#### 자료구조 관련하여
* std::vector<T> vec
    * vec은 스택 영역에 할당되지만 내부에서 사용하는 배열은 크기를 모르기 때문에 동적으로 할당 되어야 하므로 힙 영역에 할당
* std::vector<T>* vec = new vector<T>
    * 모두 힙 영역에 할당
* std::vector<T*> vec
    * 처음의 경우와 동일하지만 각각의 엘리먼트는 사용방법에 따라 힙이나 스택에 할당

## 네트워크
#### OSI 7계층
* 물리 : 시스템을 연결하기 위한 전/물리적 규격 정의
* 데이터 링크 : 시스템 간의 신뢰성 있는 전송을 보장하기 위한 계층
* 네트워크 : 노드와 노드사이에 경로를 찾아주기 위한 규격 제공
* 전송 : 컴퓨터 간의 신뢰성 있는 전송을 보장하기 위한 계층
* 세션 : 소프트웨어의 통신을 담당하기 위한 계층. TCP/IP가 여기에 속함
* 표현 : 인코딩 및 암호화
* 응용 : 데이터를 해석하고 표시하기 위한 규격 제공. HTTP와 FTP등이 여기에 속함

#### TCP/IP 4계층
OSI 7계층이 너무 세분화 되어 있어 이를 4계층으로 단순화
* 응용 : OSI 응용 + 표현. HTTP, FTP, SNMP
* 전송 : OSI 세션 + 전송. TCP, UDP
* 인터넷 : OSI 네트워크 + 데이터 링크
* 뮬라 : OSI 물리

#### 캡슐화
브라우저의 주소창에 특정 주소의 내용을 요청할 경우 TCP/IP 4계층 기준으로 다음과 같이 진행. 요청한 정보를 웹서버에서 받을 때는 반대로 진행
1. 유저 데이터
2. 유저 데이터 + TCP헤더
3. 유저 데이터 + TCP헤더 + IP헤더
4. 유저 데이터 + TCP헤더 + IP헤더 + 이더넷 헤더

#### TCP의 특징
* 연결지향 : 두 컴퓨터를 연결하는 전용의 연결회선을 생성. 세션
* 신뢰성 : 전송한 데이터를 제대로 받았는지 확인
* 전 이중 통신 : 일기 쓰기 모두 가능
* Nagle 알고리즘 사용
    * 패킷의 크기가 작을 경우 버퍼링을 통해 작은 단위의 패킷을 묶어 한 번에 보내 네트워크 부하를 줄이는 알고리즘
* TCP 헤더
    * 발신지 포트
    * 목적지 포트
    * 일련(Sequence) 번호 : 패킷의 일련 번호. 패킷의 순서 재조립 및 누락 패킷 확인
    * ACK(Acknowledge) 번호 : 신뢰성을 확보. ACK는 패킷을 잘 받았다는 것을 알려주기 위해 받은 패킷의 일련 번호에 1을 더한 값을 설정. 받은 측은 ACK 값을 확인하여 상대방이 해당 패킷을 제대로 받았는지 확인
    * TCP 헤더 길이
    * 체크섬 : 데이터의 무결성을 검사하기 위함. 전송 중에 데이터에 오류가 생겼다면 체크섬 값이 다름. 원본 체크섬 값과 비교해서 문제 검사

#### UDP의 특징
* 두 컴퓨터가 연결되지 않음. 상대방에게 일방적으로 데이터 전달
* 대량으로 빠르게 데이터 전달 가능
* 상대방이 데이터를 제대로 받았는지 확인하지 않기 때문에 신뢰성이 떨어짐
* 데이터가 중복해서 도착할 수 있음.
* UDP 헤더
    * 발신지 포트
    * 목적지 포트
    * 데이터 길이
    * 체크섬 : TCP의 체크섬과 동일

#### 패킷의 구조 예시
* 길이 + 헤더(프로토컬 넘버) + 데이터
    * 길이 : 패킷의 전체 길이를 포함하여 nagle알고리즘에서 하나의 패킷을 잘 분리할 수 있도록
    * 헤더 : 어떤 데이터인지 확인하기 위함
    * 데이터 : 실제 사용되는 정보
* 길이 + 헤더(프로토컬 넘버) + 데이터 + 엔드마커
    * 엔드마커 : 수신한 패킷의 길이에 맞게 엔드마커가 패킷의 끝에 있다면 기본적인 패킷의 유효성은 검증

#### 엔디안과 마샬링
* 엔디안은 컴퓨터 메모리에 저장된 바이트의 순서를 설명하는 용어
* 리틀엔디안과 빅엔디안이 존재
* 인텔(x86) 기반의 프로세서는 리틀엔디안
* 아톰 등은 빅엔디안
* 이런 엔디안 문제를 해결하기 위한 기술이 마샬링
    * htonl, htons, ntohl, ntohs

#### 패킷 암호화
* XOR
* DES
* google protocol buffer는 자체적으로 serialize기능을 제공. 어떤 알고리즘인지는 모름

#### 일반적인 socket 모델
1. Select 모델
    * Iterative Server + Non-Blocking Socket + Sync I.O + Async Notification
2. WSAAsyncSelect 모델
    * Iterative Server + Non-Blocking Socket + Sync I.O + Sync Notification
3. WSAEventSelect 모델
    * Iterative Server + Non-Blocking Socket + Sync I.O + Async Notification
4. Overlapped 모델
    * Concurrent Server + Non-Blocking Socket + Async I.O + Async Notification
    * 입출력 완료를 이벤트를 통해 알아내는 방법
    * 입출력 완료를 완료 루틴(콜백 함수)를 사용해서 알아내는 방법
5. IOCP 모델
    * Concurrent Server + Non-Blocking Socket + Async I.O + Async Notification
    * 효율적인 스레드 사용으로 가장 좋은 성능을 내도록 구현

#### 각 모델들의 장점
* Select 모델 
    * 모든 윈도우 버전은 물론 유닉스에서도 사용할 수 있으므로 이식성이 높다.
* WSAAsyncSelect 모델 
    * 소켓 이벤트를 윈도우 메시지 형태로 처리하므로, GUI 애플리케이션과 잘 결합 할 수 있다.
* WSAEventSelect 모델 
    * Select 모델과 WSAAsyncSelect 모델의 특성을 혼합한 형태로, 비교적 뛰어난 성능을 제공하면서 윈도우를 필요로 하지 않는다.
* Overlapped 모델(Ⅰ)
    * WSAEventSelect 모델과 비슷하지만 비동기 입출력을 통해 성능이 뛰어나다.
* Overlapped 모델(Ⅱ)
    * 비동기 입출력을 통해 성능이 뛰어나다. ( APC Queue )
* Comlpetion Port 모델 ( IOCP )
    * 비동기 입출력과 완료포트를 통해 가장 뛰어난 성능을 제공한다.

#### 각 모델들의 단점
* Select 모델
    * 하위 호환성을 위해 존재하며, 성능은 여섯 가지 모델 중 가장 떨어진다. 
    * 64개 이상의 소켓을 처리하려면 여러개의 스레드를 사용해야 한다.
* WSAAsyncSelect 모델
    * 하나의 윈도우 프로시저에서 일반 윈도우 메시지와 소켓 메시지를 처리해야 하므로 성능저하의 요인이 된다.
* WSAEventSelect 모델
    * 64개 이상의 소켓을 처리하려면 여러 개의 스레드를 사용해야 한다.
* Overlapped 모델(Ⅰ)
    * 64개 이상의 소켓을 처리하려면 여러 개의 스레드를 사용해야 한다. 
* Overlapped 모델(Ⅱ)
    * 모든 비동기 소켓 함수에 대해 완료 루틴을 사용 할 수 있는 것은 아니다.
* Comlpetion Port 모델
    * 가장 단순한 소켓 입출력 방식( 블로킹 소켓 + 스레드 )와 비교하면 코딩이 복잡하지만 성능면에서 특별한 단점이 없다.
    * 윈도우 NT계열에서만 사용할 수 있다.

#### 동기 입출력과 비동기 입출력 모델의 성능
* Select, WSAAsyncSelect, WSAEventSelect  
    * 동기 입출력을 사용하므로 성능면에서 비동기 입출력 모델에 비해서 떨어진다.
* Overlapped(Ⅰ), Overlapped(Ⅱ), Comlpetion Port (IOCP) 
    * 비동기 입출력을 사용하므로 성능이 높다.
    
#### 소켓 입출력 모델이 요구되는 사항
1. 소켓 함수 호출 시 블로킹을 최소화한다.
    * 여섯가지 모델 모두 만족한다.
2. 입출력 작업을 다른 작업과 병행한다.
    * 비동기 입출력 방식을 사용하는 Overlapped 모델(Ⅰ), Overlapped 모델(Ⅱ), Comlpetion Port 모델만 만족한다.
3. 스레드 개수를 최소화한다.
    * 여섯가지 모델 모두 어느정도 만족한다.
    * 64개 이상의 소켓을 만들시에는 WSAAsyncSelect 모델, Overlapped 모델(Ⅱ), Comlpetion Port 모델을 제외하고는 
    * 스레드를 추가로 생성한다.
    * 하지만 WSAAsyncSelect 모델은 스레드 개수가 늘어나면 성능이 상당히 떨어져서 Overlapped 모델(Ⅱ), Comlpetion Port 모델만 
    * 이 조건을 만족한다. ( IOCP는 CPU 개수에 비례하여 작업자 스레드를 생성할 수 있으므로 가장 이상적이다. )
4. 유저모드와 커널모드 전환 횟수와 데이터 복사를 최소화한다.
    * 비동기 입출력 방식을 사용하는 모델만 이 조건을 만족한다. 
    * 비동기 입출력을 할대 송신버퍼나 수신버퍼가 가득차면, 윈도우 운영체제는 애플리케이션 버퍼를 잠근후(lock), 
    * 이 메모리 영역을 직접 접근한다. 
    * 따라서 유저영역 ↔ 커널 영역 복사가 불필요하며 모드 전환없이 입출력 작업을 곧바로 이루므로 효율적이다.

※ 결론은 위의 모든 조건을 만족하는 모델은 Overlapped 모델(Ⅱ)과 IOCP 모델뿐이다. 하지만 성능 면에서 IOCP가 좋기 때문에 거의 모든 Server는 IOCP로 만든다.( 그 이외의 것을 사용한다는 소리는 들은 적이 없다. ) 


#### 멀티 쓰레드에서 동기화 방법
1. 크리티컬 섹션 (critical section)
    * 유저모드 동기화 객체 : 커널모드 동기화 객체에 비해 상대적으로 빠르다
    * 커널모드 객체가 아니기 때문에 가볍고 같은 프로세스내의 스레드 동기화에 사용
2. 뮤텍스 (mutex)
    * 커널모드 동기화 객체
    * 크리티컬 섹션보다는 느리지만 프로세스를 넘어서 모든 스레드에 사용
    * 뮤텍스를 신호상태로 생성한 후 스레드에서 wait를 호출하면 뮤텍스는 비신호 상태가 되어 다른 스레드에서의 접근을 방지
3. 세마포어 (semaphore)
    * 커털모드 동기화 객체
    * 뮤텍스와 비슷하지만 접근할 수 있는 스레드의 수를 지정
    * 세마포어를 생성할 때 3개의 스레드들이 접근 가능하도록 지정하면 내부 카운트는 3
    * 객체 내부적으로 카운트를 관리하며 세마포어 객체를 wait하는 스레드가 있으면 카운트 감소. 카운트가 0이되면 신호상태로 변경
    * 세마포어 생성 시 접근 가능한 스레드를 0으로 설정하여 WaitforSingleObject와 같은 효과를 내어 사용하기도 함
4. 스핀락 (spin lock)
    * 다른 스레드가 lock을 소융하고 있다면 lock이 반환될 때 까지 계속 확인하며 대기
    * 조금 기다리더라도 컨텍스트 스위칭으로 발생하는 부하를 최소화
    * Lock을 얻을 수 없다면 계속 lock을 확인하며 얻을 때 까지 대기. busy wait
    * Busy wait : 무한루프를 계속 반복하면서 CPU 자원을 다른 스레드에 양보하지 않음
    * Lock이 사용가능한 순간이 오면 컨텍스트 스위칭을 줄여 CPU의 부담을 감소
    * 하나의 CPU나 하나의 코어만 있는 경우에는 유용하지 않다. 싱글 CPU에서는 다른 스레드가 lock을 가지고 있고 그 스레드가 lock을 풀어주려면 어차피 컨텍스트 스위칭이 발생

#### 컨텍스트 스위칭 (context switching)
* 프로세스 A와 비가 존재한다. A가 running, B는 ready 상태라고 가정하자. 이 때 어떤 이유로 A가 ready가 되고 B가 running이 되는 상태가 발생하게 된다. 먼저 실행 중이던 A의 데이터는 현재 레지스터에 존재할 것이다. 그리고 ready 상태인 B의 데이터는 메모리에 존재할 것이다. 하지만 이제 B가 실행되어야 하기 때문에 A는 레지스터를 B에 양보해야한다. 레지스터에 올라가 있던 A의 데이터는 B가 실행을 마친 후에 A가 잘 실행될 수 있도록 메모리에 저장되어야 한다.
* 메모리는 각 프로세서가 갖고 있는 공간, 레지스터는 실제로 처리하기 위한 CPU공유공간이라고 이해하면 좀 쉬울 듯??? 좀 더 알아보자


#### 데드락 (dead lock)의 발생 조건
* 상호 배제 : 자원은 한 번에 한 프로세스만이 사용할 수 있어야 한다
* 점유 대기 : 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 있어야 한다
* 비선점 : 다른 프로세스에 할당된 자원은 사용이 끝날 때 까지 강제로 빼앗을 수 없어야 한다
* 순환 대기 : 프로세스의 집합 {P0, P1 ~ PN}에서 P0는 P1이 점유한 자원을 대기하고 P1은 P2가 점유한 자원을 대기하고... 계속되는 연결 관계


#### 데드락 (dead lock)의 처리
* 교차가 상태 예방 및 회피 : 교착 상태가 도지 않도록 보장하기 위하여 교착 상태를 예방하거나 회피하는 프로토콜을 이용하는 방법
* 교착 상태 탐지 및 회복 : 교착 상태가 되도록 허용한 다음에 회복시키는 방법
* 교착 상태 무시 : 대부분의 시스템은 교착 상태가 잘 발생하지 않으며, 교착 상태 예방, 회피, 탐지, 복구하는 것은 비용이 많이 든다


#### 교착 상태 예방
* 교착 상태 발생 조건 중 하나를 제거함으로써 해결하는 방법
* 자원의 낭비가 심함


#### C++ : 가상함수 테이블
* C++은 다형성(Polymophism)을 지원하기 위해서 가상(virtual) 키워드를 제공
* 부모가 virtual function을 갖고 있다면 자식에서 해당 함수를 재정의해서 사용할 수 있다
* 런타입 시점까지는 부모의 함수가 실행될 지 자식의 함수가 실행될 지 모른다
* 런타임에 자신의 클래스에 맞는 함수를 찾아서 호출하기 위해 존재하는 것이 가상함수 테이블(vftbl)
* virtual을 갖고 있는 클래스는 컴파일 시에 자동으로 vftbl(array)을 생성하여 실제로 실행할 함수의 주소값을 저장
* 떄문에 virtual을 갖고 있는 클래스는 항상 4byte가 기본으로 추가. vftbl 포인터.


#### X3::BehaviorTree
* *.xml파일에서 하나씩 노드를 생성
* _DECLARE_BT_STATE : 현재 AI객체의 상태를 가져오기 위한
* _DECLARE_BT_NODE : 현재 AI객체가 사용하고 있는 AI_Node의 값